{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cae2502",
   "metadata": {},
   "source": [
    "# 🧠 Introducción a NLTK en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade47e5",
   "metadata": {},
   "source": [
    "NLTK es una biblioteca poderosa para trabajar con texto humano. Permite realizar tareas como tokenización, eliminación de palabras vacías, análisis gramatical, lematización, y más."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe4d6d",
   "metadata": {},
   "source": [
    "1. 📦 Instalación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcaa806",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db8001",
   "metadata": {},
   "source": [
    "Escrito con Python, NLTK presenta una variedad de funcionalidades de manipulación de cadenas. Es una biblioteca de lenguaje natural versátil con un vasto repositorio de modelos para varias aplicaciones de lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b1457",
   "metadata": {},
   "source": [
    "2. Configurar NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69659c38",
   "metadata": {},
   "source": [
    "NLTK, sin embargo, presenta una variedad de conjuntos de datos que sirven como base para nuevos modelos de lenguaje natural. Para acceder a ellos, debe activar el descargador de datos integrado de NLTK.\n",
    "\n",
    "Entonces, una vez que haya instalado NLTK con éxito, abra su archivo Python usando cualquier editor de código.\n",
    "\n",
    "Luego importe el módulo nltk y cree una instancia del descargador de datos con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75c4d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1d71c",
   "metadata": {},
   "source": [
    "Al ejecutar el código anterior a través del terminal, aparece una interfaz gráfica de usuario para seleccionar y descargar paquetes de datos. Aquí, deberá elegir un paquete y hacer clic en el botón Descargar para obtenerlo.\n",
    "\n",
    "Cualquier paquete de datos que descargue va al directorio especificado escrito en el campo Directorio de descarga . Puede cambiar esto si lo desea. Pero intente mantener la ubicación predeterminada en este nivel.\n",
    "\n",
    "Nota: Los paquetes de datos se adjuntan a las variables del sistema de forma predeterminada. Por lo tanto, puede seguir usándolos para proyectos posteriores independientemente del entorno de Python que esté usando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98cfea",
   "metadata": {},
   "source": [
    "4. Cómo utilizar tokenizadores NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f3dd7",
   "metadata": {},
   "source": [
    "En última instancia, NLTK ofrece modelos de tokenización entrenados para palabras y oraciones. Con estas herramientas, puede generar una lista de palabras a partir de una oración. O transforma un párrafo en una matriz de oraciones sensata.\n",
    "\n",
    "A continuación, se muestra un ejemplo de cómo utilizar el tokenizador de palabras NLTK :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07ff0a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'an', 'example', 'text']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word = \"This is an example text\"\n",
    "tokenWord = word_tokenize(word)\n",
    "print(tokenWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ab89e",
   "metadata": {},
   "source": [
    "NLTK también usa un tokenizador de oraciones previamente entrenado llamado PunktSentenceTokenizer . Funciona dividiendo un párrafo en una lista de oraciones.\n",
    "\n",
    "Veamos cómo funciona esto con un párrafo de dos oraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1f8fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example text.', 'This is a tutorial for NLTK']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, PunktSentenceTokenizer\n",
    "\n",
    "sentence = \"This is an example text. This is a tutorial for NLTK\"\n",
    "token = PunktSentenceTokenizer()\n",
    "tokenized_sentence = token.tokenize(sentence)\n",
    "print(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86e9bb",
   "metadata": {},
   "source": [
    "# Ejemplos de cómo utilizar NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632d9299",
   "metadata": {},
   "source": [
    "Entonces, si bien no podemos demostrar todos los casos de uso posibles de NLTK, aquí hay algunos ejemplos de cómo puede comenzar a usarlo para resolver problemas de la vida real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374896b",
   "metadata": {},
   "source": [
    "# Obtenga definiciones de palabras y sus partes del discurso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d995bb",
   "metadata": {},
   "source": [
    "NLTK presenta modelos para determinar las partes del discurso, obtener semántica detallada y el posible uso contextual de varias palabras.\n",
    "\n",
    "Puede utilizar el modelo de wordnet para generar variables para un texto. Luego determine su significado y parte del discurso.\n",
    "\n",
    "Por ejemplo, revisemos las posibles variables de \"Monkey:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac9821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('monkey.n.01'), Synset('imp.n.02'), Synset('tamper.v.01'), Synset('putter.v.02')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "print(wn.synsets('monkey'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fe148",
   "metadata": {},
   "source": [
    "El código anterior genera posibles alternativas de palabras o sintaxis y partes de la oración para \"Monkey\".\n",
    "\n",
    "Ahora verifique el significado de \"Mono\" usando el método de definición :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c5ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any of various long-tailed primates (excluding the prosimians)\n"
     ]
    }
   ],
   "source": [
    "Monkey = wn.synset('monkey.n.01').definition()\n",
    "print(Monkey)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
